{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e254b06",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Installation (run these first if needed) ---\n",
    "# !pip install torch transformers\n",
    "# !pip install bertviz\n",
    "\n",
    "# --- Imports ---\n",
    "import torch\n",
    "from transformers import BertTokenizer, BertForMaskedLM, BertModel\n",
    "from bertviz import head_view\n",
    "\n",
    "# --- Step 2: Load Model and Helper Function ---\n",
    "\n",
    "# Load the pre-trained model and tokenizer for Masked LM\n",
    "print(\"Loading models for Masked Language Modeling...\")\n",
    "tokenizer_mlm = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "model_mlm = BertForMaskedLM.from_pretrained('bert-base-uncased')\n",
    "model_mlm.eval() # Set the model to evaluation mode\n",
    "\n",
    "def predict_masked_word(text, top_k=5):\n",
    "    \"\"\"\n",
    "    Given a text with a [MASK] token, predicts the top_k most likely words \n",
    "    to fill the mask.\n",
    "    \"\"\"\n",
    "    # Tokenize the input\n",
    "    inputs = tokenizer_mlm(text, return_tensors=\"pt\")\n",
    "    mask_token_index = torch.where(inputs[\"input_ids\"] == tokenizer_mlm.mask_token_id)[1]\n",
    "\n",
    "    # Get model outputs (logits)\n",
    "    with torch.no_grad():\n",
    "        outputs = model_mlm(**inputs)\n",
    "        predictions = outputs.logits\n",
    "\n",
    "    # Get the top_k predictions for the masked token\n",
    "    masked_token_logits = predictions[0, mask_token_index.item()]\n",
    "    top_k_indices = torch.topk(masked_token_logits, top_k, dim=0).indices\n",
    "    top_k_tokens = tokenizer_mlm.convert_ids_to_tokens(top_k_indices)\n",
    "    \n",
    "    return top_k_tokens\n",
    "\n",
    "print(\"MLM Model and helper function ready.\\n\")\n",
    "\n",
    "# --- Step 3: Exploration and Analysis ---\n",
    "\n",
    "print(\"--- Running Exploration and Analysis ---\")\n",
    "\n",
    "# Test Case 1: Basic Factual Knowledge\n",
    "text_1 = \"The capital of France is [MASK].\"\n",
    "predictions_1 = predict_masked_word(text_1)\n",
    "print(f\"Text: {text_1}\")\n",
    "print(f\"Predictions: {predictions_1}\\n\")\n",
    "\n",
    "# Test Case 2a: Semantic Context (Medical)\n",
    "text_2a = \"The doctor prescribed the [MASK] to the patient.\"\n",
    "predictions_2a = predict_masked_word(text_2a)\n",
    "print(f\"Text: {text_2a}\")\n",
    "print(f\"Predictions: {predictions_2a}\\n\")\n",
    "\n",
    "# Test Case 2b: Semantic Context (Automotive)\n",
    "text_2b = \"The mechanic checked the [MASK] of the car.\"\n",
    "predictions_2b = predict_masked_word(text_2b)\n",
    "print(f\"Text: {text_2b}\")\n",
    "print(f\"Predictions: {predictions_2b}\\n\")\n",
    "\n",
    "# Test Case 3: Syntactic and Long-Range Context\n",
    "text_3 = \"All the players on the team celebrated after [MASK] won the championship.\"\n",
    "predictions_3 = predict_masked_word(text_3)\n",
    "print(f\"Text: {text_3}\")\n",
    "print(f\"Predictions: {predictions_3}\\n\")\n",
    "\n",
    "print(\"--- Analysis Complete ---\\n\")\n",
    "\n",
    "# --- Step 5: Visualization of Results ---\n",
    "\n",
    "print(\"--- Setting up Visualization ---\")\n",
    "# We need BertModel (not ForMaskedLM) to get attention outputs\n",
    "model_viz = BertModel.from_pretrained('bert-base-uncased', output_attentions=True)\n",
    "tokenizer_viz = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "\n",
    "# Process input\n",
    "text_viz = \"He sat on the river bank.\"\n",
    "inputs_viz = tokenizer_viz(text_viz, return_tensors='pt')\n",
    "outputs_viz = model_viz(**inputs_viz)\n",
    "attention = outputs_viz.attentions  # This is a tuple of 12 (layers) tensors\n",
    "\n",
    "print(f\"Visualization ready for text: '{text_viz}'\")\n",
    "print(\"Run the 'head_view' function below in a Jupyter Notebook to see the visualization.\")\n",
    "\n",
    "# Display visualization\n",
    "# This command must be run in a Jupyter Notebook cell to render the interactive UI.\n",
    "head_view(attention, tokenizer_viz.convert_ids_to_tokens(inputs_viz['input_ids'][0]))"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
